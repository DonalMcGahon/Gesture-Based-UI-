# **Gesture-Based-UI**

## **Repository Table of Contents**
1. [Project Specification](https://github.com/DonalMcGahon/Gesture-Based-UI-#project-specification)
1. [Purpose of the application](https://github.com/DonalMcGahon/Gesture-Based-UI-#purpose-of-the-application)
1. [Purpose](https://github.com/Smurfgalway/Final-Year-Project-Applied-Diss#technologies)
1. [How it works](https://github.com/Smurfgalway/Final-Year-Project-Applied-Diss#architecture)
1. [Project Specification](https://github.com/DonalMcGahon/Gesture-Based-UI-#project-specification)
1. [Purpose of the application](https://github.com/DonalMcGahon/Gesture-Based-UI-#purpose-of-the-application)
1. [Purpose](https://github.com/Smurfgalway/Final-Year-Project-Applied-Diss#technologies)
1. [How it works](https://github.com/Smurfgalway/Final-Year-Project-Applied-Diss#architecture)

### **Project Specification:**
Develop an application with a Natural User Interface. You have a choice of technologies available to you and an opportunity to combine a lot of technology that you have worked with over the past four years.

At the very least, this should be a local implementation of the application using gestures to interact with it. You can expand out to include real-world hardware and use this as an opportunity to prove a concept. The Internet of Things is a common phrase, so you could implement a solution taking advantage of hardware like the Raspberry Pi, using the cloud for data transfer and creating a realworld scenario through this medium.

The programming language is your choice and there are several options including JavaScript C#, C++ and Lua.

## **Purpose of the application:**
### **Purpose:**

The purpose of this application is to allow the user to interact with muliple instruments by using gestures. The user will be able to select a certain instrument, weather it be a piano, guitar, drum set or trumpet, and create sounds using gestures with these instruments. As well as creating sounds the user will be able to record the music they created and play it back.

### **How it works:**

The application is a Windows universal app, so the application is launched using Visual Studio. The user of the application must have a [Myo Armband](https://www.myo.com/) to interact with the application. When the app is launched the user is greeted with an opening page displaying a curtain and a hamburger view. Inside the hamburger view the user can navigate to 4 different instruments which include a piano, a guitar, drum set and a trumpet. Once the user navigates to any of these instruments, the instrument itself will appear on the screen and the user can now use that instrument and create sounds. The user makes gestures to interact with the instrument they have choosen. The gestures that are avaliable with the myo armband are creating a "Fist", "Finger tap", "Finger spread", "Wave out" and "Wave in". All of these gestures will create a sound with the instrument the user has choosen. When the user chooses, they can record the sounds they are making with the instrument by pressing the record button on the bottom of the screen. Once finished recording they can press stop. To play back the music they just created they can press the play button.

### **User Interface:**

The user interface has a simple user friendly appeal. Their is a hamburger view on the left hand panel. The user can click this hanburger view and it will have a list of instruments for the user to choose from. 1 - Piano, 2 - Guitar, 3 - Drums, 4 - Trumpet.
The users can navigate from one instrument to the next using this hamburger view.
On the bottom of each of the instruments xaml pages their is a bottom app bar. On this bar is the record, stop and play buttons.

### __Screenshots of user interface:__

#### Piano:

![image](https://user-images.githubusercontent.com/14197773/37923388-efae2726-3126-11e8-8b8c-20e329b557fe.png)

#### Guitar:
![image](https://user-images.githubusercontent.com/14197773/37923454-1221d7d0-3127-11e8-8add-7dda87f9ca88.png)

#### Drums:
![image](https://user-images.githubusercontent.com/14197773/37923517-35f6c1a2-3127-11e8-9cb0-12e3bcc0a4f3.png)

#### Trumpet:
![image](https://user-images.githubusercontent.com/14197773/37923597-68fcd942-3127-11e8-86c8-d7ef2496148b.png)


## **Gestures identified as appropriate for this application:**
Consider how gestures can be incorporated
into the application, making a justified argument for the ones that you pick. This is a research
element for the project.

## **Hardware used in creating the application:**
You are not limited to the hardware listed above. If
you have your own hardware, or hardware simulator that you wish to use, then feel free. The
purpose of each piece of hardware should be given with a comparison to other options available.

## **Architecture for the solution:**
The full architecture for the solution, including the class diagrams,
any data models, communications and distributed elements that you are creating.

## **Conclusions & Recommendations:**
Conclusions are what you have learned from this project and
the associated research. Recommendations are what you would do differently if you were to
undertake the project again. The Reflective Piece – what I learned and “enjoyed” 